> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [blog.csdn.net](https://blog.csdn.net/brightming/article/details/119924999?spm=1001.2014.3001.5502)

![](https://img-blog.csdnimg.cn/1a01f9a642604c0db6742f86a0c64d3a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBAYnJpZ2h0bWluZw==,size_32,color_FFFFFF,t_70,g_se,x_16)

1、为什么要将 e(x) 写成 e(x+dx) 的形式？  
2、J(x) 是什么对什么的导数？

理解  
1、形式上来说，e(x) 和 e(x+dx) 并没有任何区别，以为 dx 本身就是小量，只要 x+dx 还在[作用域](https://so.csdn.net/so/search?q=%E4%BD%9C%E7%94%A8%E5%9F%9F&spm=1001.2101.3001.7020)？内，函数的意思就是一样的。  
更土一点的解析，假设定义域是在 [-100,100]，那么只要 x+dx 在这个范围内，函数表示的意思就一样。

既然意思一样，为何要写成这个形式？  
因为我们接下来要做的是进行迭代优化，迭代优化需要指定一个起点，即这里的 e(x+dx) 的 x 在某次迭代中，是固定的，那么 e(x+dx) 就变成了 dx 的函数了。  
为何要把原本是 x 的函数变成是 dx 的函数呢？  
迭代的含义是，在每一步都找到最好的变化量。像这个公式，在某次迭代中指定了 x，使得 e(x+dx) 在 x=x0 附近，这段小范围的曲线（假设 e(x) 是一个曲线），最低点在哪里？只需要对 dx 求导就可以得知了。

2、J 是谁对谁的？  
这里的 J 是函数 e(x) 对 x 的求导。上面说了，迭代会指定一个 x=x0，在这里开始处理，找到最优的一个 dx，将 dx 叠加到 x 上，形成新的 x1，再继续。  
所以，这个 J 描述的是在 x=x0 处，函数 e(x) 的导数的具体的值，这个具体的值描述了变量随自变量的变化程度，而 dx 就是自变量的变化程度。  
用 J 也是对 e(x) 这个函数的线性化的方法，用了这个方法后，可以将 e(x+dx) 展开成为 dx 的函数:  
e(x+dx)=e(x)+J*dx，因为这里的 x 是指定的等于 x0，J 是可以计算的，所以在某次迭代中整个就成为了：e(x0)+J(x0)_dx，就是 dx 的函数。  
如果要优化的就是这个 e(x0)+J(x0)_dx, 好像没法开展，所以会有最小二乘，即：  
(e(x0)+J_dx) * (e(x0)+J_dx)  
这个展开来就是关于 dx 的二次函数了，对 dx 求导并令导数为 0，即可求出 dx 的值。

求出的这个 dx 的值含义是什么？  
就是在该次迭代中，指定的 x0 附近对应的那段曲线，如果 x0 加上计算出来的 dx，就可以得到这一小段曲线的最小值。为什么不是整体的最小值？因为 J 是对原函数 e(x) 的线性近似，只有在展开点（某次迭代点 x0）处的近似才是相对准确的。当然如果 e(x) 本身就是线性函数，那也不用这么麻烦了，直接求导就可以知道了。

通过上面逐次迭代，不断的找出一小段曲线的对应的最低点，最终逼近整段曲线的最低点。

如果曲线是多波浪的，初值的取值就非常重要，不然就可能最终停留在非全局最低的地方，这也是为什么用 imu 来做预估，再用点云匹配的原因。让点云匹配在合适的地方进行。  
尤其是对应阶梯，每个阶梯都是一样的，如果没有准确的估计值（估计值离真值差距起码小于半个阶梯），那么就可能错位匹配了。

3、再补充一个问题  
对于 f (x) = x 2 + 3 x f(x)=x^2 +3x f(x)=x2+3x  
怎么找极值？  
直接求导。 上面的最小二乘，就是将 e 2 (x) e^2(x) e2(x)  
通过指定迭代点展开成： e 2 ( x + d x ) e^2(x+dx) e2(x+dx) 指定展开点 x0，变成：  
e 2 ( x 0 + d x ) e^2(x_0+dx) e2(x0​+dx)  
得到类似上二次方程的形式，得到 x（即 dx）。

就是说，在将原问题在某点展开线性化后，就成为了简单的求导求极值计算的问题。

当然，如果就要对 f (x) = x 2 + 3 x f(x)=x^2+3x f(x)=x2+3x 利用迭代方式求解，也可以。用梯度方法，不断逼近。  
即，同样假设一个初值 x0, 计算该处的梯度，然后指定一个步长 lamda，计算下一个点：  
x1=x0-f’(x0)*lamda .  
直到满足要求为止。  
不过显然，对于这种简单凸函数，简单处理即可。